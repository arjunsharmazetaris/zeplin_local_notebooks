{
  "paragraphs": [
    {
      "title": "Introduction",
      "text": "%md\n\n# Introduction\n\n[Apache Flink](https://flink.apache.org/) is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. This is Flink tutorial for running classical wordcount in both batch and streaming mode. \n\nThere're 3 things you need to do before using flink in Zeppelin.\n\n* Download [Flink 1.10 or afterwards](https://flink.apache.org/downloads.html)  (Only 1.10 afterwards are supported), unpack it and set `FLINK_HOME` in Flink interpreter setting to this location.\n* Copy flink-python_2.11\u2013x.x.x.jar from flink opt folder to flink lib folder (it is used by Pyflink which is supported in Zeppelin)\n* If you want to run yarn mode, you need to set `HADOOP_CONF_DIR` in flink interpreter setting. And make sure `hadoop` is in your `PATH`, because internally Flink will call command `hadoop classpath` and put all the hadoop related jars on the classpath of Flink interpreter process.\n\nThere're 6 sub interpreters in Flink interpreter, each is used for different purpose. However they are in the the JVM and share the same ExecutionEnviroment/StremaExecutionEnvironment/BatchTableEnvironment/StreamTableEnvironment.\n\n\n* `%flink`\t- Creates ExecutionEnvironment/StreamExecutionEnvironment/BatchTableEnvironment/StreamTableEnvironment and provides a Scala environment \n* `%flink.pyflink`\t- Provides a python environment \n* `%flink.ipyflink`\t- Provides an ipython environment \n* `%flink.ssql`\t - Provides a stream sql environment \n* `%flink.bsql`\t- Provides a batch sql environment ",
      "user": "anonymous",
      "dateUpdated": "Jul 26, 2021, 4:41:59 AM",
      "progress": 0,
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "title": false,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Introduction</h1>\n<p><a href=\"https://flink.apache.org/\">Apache Flink</a> is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams. This is Flink tutorial for running classical wordcount in both batch and streaming mode.</p>\n<p>There&rsquo;re 3 things you need to do before using flink in Zeppelin.</p>\n<ul>\n<li>Download <a href=\"https://flink.apache.org/downloads.html\">Flink 1.10 or afterwards</a>  (Only 1.10 afterwards are supported), unpack it and set <code>FLINK_HOME</code> in Flink interpreter setting to this location.</li>\n<li>Copy flink-python_2.11\u2013x.x.x.jar from flink opt folder to flink lib folder (it is used by Pyflink which is supported in Zeppelin)</li>\n<li>If you want to run yarn mode, you need to set <code>HADOOP_CONF_DIR</code> in flink interpreter setting. And make sure <code>hadoop</code> is in your <code>PATH</code>, because internally Flink will call command <code>hadoop classpath</code> and put all the hadoop related jars on the classpath of Flink interpreter process.</li>\n</ul>\n<p>There&rsquo;re 6 sub interpreters in Flink interpreter, each is used for different purpose. However they are in the the JVM and share the same ExecutionEnviroment/StremaExecutionEnvironment/BatchTableEnvironment/StreamTableEnvironment.</p>\n<ul>\n<li><code>%flink</code>\t- Creates ExecutionEnvironment/StreamExecutionEnvironment/BatchTableEnvironment/StreamTableEnvironment and provides a Scala environment</li>\n<li><code>%flink.pyflink</code>\t- Provides a python environment</li>\n<li><code>%flink.ipyflink</code>\t- Provides an ipython environment</li>\n<li><code>%flink.ssql</code>\t - Provides a stream sql environment</li>\n<li><code>%flink.bsql</code>\t- Provides a batch sql environment</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1580997898536_-1239502599",
      "id": "paragraph_1580997898536_-1239502599",
      "dateCreated": "Feb 6, 2020, 10:04:58 PM",
      "dateStarted": "Jul 26, 2021, 4:41:59 AM",
      "dateFinished": "Jul 26, 2021, 4:41:59 AM",
      "status": "FINISHED"
    },
    {
      "title": "Batch WordCount",
      "text": "%flink\n\nval data = benv.fromElements(\"hello world\", \"hello flink\", \"hello hadoop\")\ndata.flatMap(line => line.split(\"\\\\s\"))\n             .map(w => (w, 1))\n             .groupBy(0)\n             .sum(1)\n             .print()\n",
      "user": "anonymous",
      "dateUpdated": "Jul 26, 2021, 4:39:20 AM",
      "progress": 0,
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdata\u001b[0m: \u001b[1m\u001b[32morg.apache.flink.api.scala.DataSet[String]\u001b[0m = org.apache.flink.api.scala.DataSet@2d73af10\n(flink,1)\n(hadoop,1)\n(hello,3)\n(world,1)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "http://localhost:8083#/job/3e3862199e3e9ce97cfa7f115d63242f"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1580998080340_1531975932",
      "id": "paragraph_1580998080340_1531975932",
      "dateCreated": "Feb 6, 2020, 10:08:00 PM",
      "dateStarted": "Jul 26, 2021, 4:39:20 AM",
      "dateFinished": "Jul 26, 2021, 4:39:42 AM",
      "status": "FINISHED"
    },
    {
      "title": "Streaming WordCount",
      "text": "%flink\n\nval data = senv.fromElements(\"hello world\", \"hello flink\", \"hello hadoop\")\ndata.flatMap(line => line.split(\"\\\\s\"))\n  .map(w => (w, 1))\n  .keyBy(0)\n  .sum(1)\n  .print\n\nsenv.execute()",
      "user": "anonymous",
      "dateUpdated": "Jul 26, 2021, 4:39:42 AM",
      "progress": 0,
      "config": {
        "colWidth": 6.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mdata\u001b[0m: \u001b[1m\u001b[32morg.apache.flink.streaming.api.scala.DataStream[String]\u001b[0m = org.apache.flink.streaming.api.scala.DataStream@5814d5e0\n\u001b[33mwarning: \u001b[0mthere was one deprecation warning; re-run with -deprecation for details\n\u001b[1m\u001b[34mres2\u001b[0m: \u001b[1m\u001b[32morg.apache.flink.streaming.api.datastream.DataStreamSink[(String, Int)]\u001b[0m = org.apache.flink.streaming.api.datastream.DataStreamSink@5c76bd7d\n(hello,1)\n(world,1)\n(hello,2)\n(flink,1)\n(hello,3)\n(hadoop,1)\n\u001b[1m\u001b[34mres3\u001b[0m: \u001b[1m\u001b[32morg.apache.flink.api.common.JobExecutionResult\u001b[0m =\nProgram execution finished\nJob with JobID 27af9c543e20d02098d66e0900526361 has finished.\nJob Runtime: 152 ms\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "FLINK JOB",
          "tooltip": "View in Flink web UI",
          "group": "flink",
          "values": [
            {
              "jobUrl": "http://localhost:8083#/job/27af9c543e20d02098d66e0900526361"
            }
          ],
          "interpreterSettingId": "flink"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1580998084555_-697674675",
      "id": "paragraph_1580998084555_-697674675",
      "dateCreated": "Feb 6, 2020, 10:08:04 PM",
      "dateStarted": "Jul 26, 2021, 4:39:42 AM",
      "dateFinished": "Jul 26, 2021, 4:39:48 AM",
      "status": "FINISHED"
    },
    {
      "text": "%flink\n",
      "user": "anonymous",
      "dateUpdated": "Feb 25, 2020, 11:10:14 AM",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1582600214095_1825730071",
      "id": "paragraph_1582600214095_1825730071",
      "dateCreated": "Feb 25, 2020, 11:10:14 AM",
      "status": "READY"
    }
  ],
  "name": "1. Flink Basics",
  "id": "2F2YS7PCE",
  "defaultInterpreterGroup": "flink",
  "version": "0.9.0-SNAPSHOT",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {},
  "path": "/Flink Tutorial/1. Flink Basics"
}